---
title: "Análise de Resíduos em Modelos de Regressão Linear"
date: 2019-09-10
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>O modelo de regressão linear é bastante usado na predição de variáveis contínuas, onde há uma ou mais variáveis independentes buscando mapear o comportamento de uma variável dependente. O modelo é bastante simples e lembro ser um dos primeiros a ser ensinado nas aulas de econometria. Porém, apesar de sua simplicidade, é preciso se atentar a alguns detalhes sobre suas premissas para que os resultados deste modelo possam ser usados para a tomada de decisão.</p>
<p>Abaixo vou listar algumas premissas da regressão linear, que sendo atendidas, fazem com que o modelo gere conclusões confiáves:</p>
<ol style="list-style-type: lower-roman">
<li><p>Ausência de multicolinearidade entre as variáveis independentes.</p></li>
<li><p>Ausência de autocorrelação na variável dependente.</p></li>
<li><p>Ausência de padrão no comportamento dos resíduos do modelo, ou seja, ausência de heterocedasticidade.</p></li>
<li><p>Resíduos se distribuem de acordo com uma distribuição normal.</p></li>
</ol>
<p>Neste post vou calcular uma regressão linear simples e analisar os resíduos para ver se as premissas <strong>iii</strong> e <strong>iv</strong> estão sendo atendidas. Para começar, vamos trazer os pacotes necessários no R:</p>
<pre class="r"><code>library(tidyverse)
library(lmtest)
library(corrplot)
library(readxl)</code></pre>
<p>O exemplo que tenho apresenta dados de preço e oferta de cana de açúcar. A variável independente é o preço da cana de açúcar e a variável dependente é a área plantada deste produto, que representando uma proxy para sua oferta. O objetivo da regressão será quantificar a elasticidade da oferta em função do preço, ou seja, quantificar quão sensível é a oferta da cana de açúcar quando ocorre uma variações em seu preço. Os dados deste exercício estão no meu repositório do Github, vamos trazê-los com o comando abaixo, salvando-os na variável df:</p>
<pre class="r"><code>df &lt;- read.csv(file = &quot;https://raw.githubusercontent.com/FranciscoPiccolo/franciscopiccolo.github.io/master/datasets/2019-09-05-residual_analysis_on_linear_regression_models/dataset_1.csv&quot;, 
               sep = &quot;;&quot;, 
               dec = &quot;,&quot;)</code></pre>
<pre class="r"><code># Amostra do dataset
df[sample(nrow(df),5), ] %&gt;%
    as_tibble()</code></pre>
<pre><code>## # A tibble: 5 x 3
##   period  area price
##    &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
## 1      2    71 0.115
## 2      4    90 0.110
## 3     26   124 0.288
## 4      5    72 0.110
## 5      8    61 0.210</code></pre>
<p>O modelo de regressão linear para este cenário será desenvolvido de acordo com a fórmula abaixo:</p>
<p><span class="math display">\[ lnY_t = \beta_0+\beta_1 (lnX_t) + \mu_t \]</span></p>
<p>Onde:</p>
<p><span class="math inline">\(Y_t\)</span> = Área plantada após a transformação com log natural (e)</p>
<p><span class="math inline">\(X_t\)</span> = Preço da cana de açúcar também após a transformação com log natural</p>
<p><span class="math inline">\(\beta_0\)</span> = Intercepto</p>
<p><span class="math inline">\(\beta_1\)</span> = Inclinação</p>
<p><span class="math inline">\(\mu_t\)</span> = Resíduos</p>
<p>Os dados precisam ter a aplicação do log natural, pois esta transformação faz com que as variações entre os períodos possam ser interpretadas como variações percentuais, e isso é necessário por conta de que a elasticidade é quantificada em termos percentuais. Esta característica ocorre apenas na transformação com logarítmo natural, se a transformação fosse feita com outros logs, a interpretação não seria válida.</p>
<p>O gráfico abaixo irá mostrar o comportamento das variáveis do dataset, bem como a curva de regressão linear, antes de aplicar a transformação log natural.</p>
<pre class="r"><code>df %&gt;% 
  ggplot()+
  geom_point(mapping = aes(x = price, y = area), shape = 2)+
  geom_smooth(mapping = aes(x = price, y = area), 
              method = &quot;lm&quot;, 
              formula = y ~ x, 
              se = F, 
              lty = 2,
              color = &quot;dark orange&quot;)+
  theme_graph()+
  labs(title = &quot;Gráfico de dispersão das variáveis&quot;,
       x = &quot;Preço da Cana de Açúcar&quot;,
       y = &quot;Área Plantada&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-5-1.png" width="288" style="display: block; margin: auto;" /></p>
<p>Podemos ver que há uma correlação positiva entre o preço do produto e sua oferta. Agora vamos aplicar o log natural no modelo de regressão. Para isso, o R nos fornece duas opções:</p>
<ul>
<li><p>Ajustar as variáveis no dataset e construir o modelo usando as variáveis ajustadas.</p></li>
<li><p>Construir o modelo e indicar “dentro dele” que é necessário fazer a transformação antes de computar os resultados.</p></li>
</ul>
<p>Vamos ver na prática como cada opção pode ser usada. O resultado final será idêntico.</p>
<p>Primeiro vou criar duas variáveis com os resultados dos dois métodos:</p>
<pre class="r"><code># Método 1, criando novos campos no dataset com a transformação log (e)
first_method &lt;- 
  df %&gt;% 
  mutate(area_log = log(area),
         price_log = log(price)) %&gt;% 
  lm(formula = area_log ~ price_log)

second_method &lt;- 
  df %&gt;% 
  lm(formula = log(area) ~ log(price))</code></pre>
<p>Com as duas variáveis criadas, vamos criar uma tabela comparando os principais resultados do modelo (i.e. coeficiente e intercepto):</p>
<pre class="r"><code>data.frame(&quot;1º Método&quot; = c(first_method$coefficients),
           &quot;2º Método&quot; = c(second_method$coefficients))</code></pre>
<pre><code>##             X1º.Método X2º.Método
## (Intercept)  6.1113284  6.1113284
## price_log    0.9705823  0.9705823</code></pre>
<p>Conforme indicado, ambos os métodos geram o mesmo valor. Eu prefiro o segundo, que exige menos linhas de código. Com base nos coeficientes estimados, temos a seguinte equação:</p>
<p><span class="math display">\[\hat{Y} = 6.11 + 0.97X_1 + \mu\]</span></p>
<p>O resultado é estatisticamente significativo, visto que tanto o intercepto quanto a inclinação apresentam um valor-p baixo. Veja abaixo estes valores bem como o R².</p>
<pre class="r"><code>second_method %&gt;% summary()</code></pre>
<pre><code>## 
## Call:
## lm(formula = log(area) ~ log(price), data = .)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.65076 -0.18823 -0.03096  0.24914  0.60492 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   6.1113     0.1686  36.254  &lt; 2e-16 ***
## log(price)    0.9706     0.1106   8.773 5.03e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3088 on 32 degrees of freedom
## Multiple R-squared:  0.7063, Adjusted R-squared:  0.6972 
## F-statistic: 76.97 on 1 and 32 DF,  p-value: 5.031e-10</code></pre>
<p>Apesar destes dados mostrarem que a reta se ajustou bem aos dados e que o modelo consegue explicar ~70% da variação na variável dependente, é preciso ainda analisar os resíduos para poder ter confiança no resultado e fazer projeções. No gráfico abaixo, vamos ver como se distribuem os resíduos do modelo.</p>
<pre class="r"><code>model_residuals &lt;- 
  data.frame(values = second_method$residuals)</code></pre>
<p>Eu opto primeiro por analisar um histograma dos reísduos, pois ele indicará se a distribuição se assemelha a uma distribuição normal. Vamos ver isso no gráfico abaixo.</p>
<pre class="r"><code># Histogram
model_residuals %&gt;% 
  ggplot()+
  geom_histogram(mapping = aes(x = values), fill = &quot;steel blue&quot;)+
  theme_graph()+
  labs(title = &quot;Distribuição dos Resíduos&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-10-1.png" width="288" style="display: block; margin: auto;" /></p>
<p>Aparentemente os resíduos se distribuem normalmente. Outro gráfico interessante para analisar é o <strong>q-q plot</strong>, que também indicará quão parecido com a distribuição normal é a distribuição de uma variável.</p>
<pre class="r"><code># q-q plot
model_residuals %&gt;% 
  ggplot()+
  geom_qq(mapping = aes(sample = values))+
  labs(title = &quot;Residuals&#39; Q-Q plot&quot;,
       x = &quot;&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="288" style="display: block; margin: auto;" /></p>
<p>Este gráfico também aponta para a ideia de resíduos normalmente distribuídos. Apesar de estes métodos serem bons e práticos, as vezes é necessário usar métodos formais para gerar uma conclusão. Para validação da independência no comportamento dos resíduos pode-se usar o teste <strong>Durbin Watson</strong>. O código abaixo realiza este teste.</p>
<pre class="r"><code># Necessário instalar e chamar o pacote &#39;lmtest&#39;
lmtest::dwtest(df %&gt;% 
                 lm(formula = log(area) ~ log(price)))</code></pre>
<pre><code>## 
##  Durbin-Watson test
## 
## data:  df %&gt;% lm(formula = log(area) ~ log(price))
## DW = 1.2912, p-value = 0.009801
## alternative hypothesis: true autocorrelation is greater than 0</code></pre>
<p>O resultado do teste foi de 1.2912, mas apenas com este valor não é possível fazer uma conclusão. Em conjunto com este valor, é preciso saber os valores limiares <strong>DL</strong> e <strong>DU</strong>, que podem ser encontrados nesta <a href="http://www.portalaction.com.br/analise-de-regressao/33-diagnostico-de-independencia">tabela</a>. Para encontrar os valores com esta tabela, basta saber o número de observações no dataset (i.e. n = 33), o nível de significância do teste (i.e. 0.05) e os graus de liberdade (i.e. 1). Com isso, tem-se:</p>
<p><strong>DL</strong> = 1.35</p>
<p><strong>DU</strong> = 1.49</p>
<p>Tendo DW igual a 1.2912, acima de 0 e abaixo de DL, pode-se concluir que os resíduos são independentes.</p>
<p>Com isso, podemos concluir que de fato o modelo é confiável para realizar projeções, pois tanto os gráficos quanto o teste formal indicam que as premissas (iii) e (iv) estão sendo atendidas. Desta forma, podemos concluir que há elasticidade na oferta de cana de açúcar com relação ao seu preço.</p>
